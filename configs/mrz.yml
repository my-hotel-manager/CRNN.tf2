dataset_builder: &ds_builder
  table_path: "datasets/table.txt"
  # If change image height(32), change the net.
  # If image width is not null, the image will be distorted.
  img_shape: [32, null, 3]
  # The image that width greater than max img_width will be dropped.
  # Only work with image width is null.
  max_img_width: 1000
  ignore_case: false

train:
  dataset_builder:
    <<: *ds_builder
  train_ann_paths:
    - "datasets/binarized/train/dataset_annotation.ssv"
    - "datasets/binarized/val/dataset_annotation.ssv"
  val_ann_paths:
    - "datasets/binarized/test/dataset_annotation.ssv"
  batch_size_per_replica: 64
  # The model for restore, even if the number of characters is different
  restore: ""
  learning_rate: 0.001
  # Number of epochs to train.
  epochs: 50
  # Reduce learning rate when a metric has stopped improving.
  # ReduceLROnPlateau Arguments
  # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau#arguments
  reduce_lr:
    factor: 0.5
    patience: 5
    min_lr: 0.0001
  # TensorBoard Arguments
  # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard#arguments_1
  tensorboard:
    histogram_freq: 1
    profile_batch: 0

eval:
  dataset_builder:
    <<: *ds_builder
  ann_paths:
    - "datasets/noisy/test/dataset_annotation.ssv"
  batch_size: 64

predict:
  dataset_builder:
    <<: *ds_builder
  ann_paths:
    - "datasets/predict/datapoint_annotation.ssv"
  batch_size: 64
